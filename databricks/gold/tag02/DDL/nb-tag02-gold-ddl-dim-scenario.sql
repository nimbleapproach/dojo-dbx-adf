# Databricks notebook source
import os

ENVIRONMENT = os.environ["__ENVIRONMENT__"]

# COMMAND ----------

spark.catalog.setCurrentCatalog(f"gold_{ENVIRONMENT}")

# COMMAND ----------

# MAGIC %sql
# MAGIC
# MAGIC -- Databricks notebook source
# MAGIC -- MAGIC %md
# MAGIC -- MAGIC Widgets are used to give Data Factory a way to hand over parameters. In that we we can control the environment.
# MAGIC -- MAGIC If there is no widget defined, Data Factory will automatically create them.
# MAGIC -- MAGIC For us while developing we can use the try and excep trick here.
# MAGIC
# MAGIC -- COMMAND ----------
# MAGIC
# MAGIC -- MAGIC %python
# MAGIC -- MAGIC import os
# MAGIC -- MAGIC
# MAGIC -- MAGIC ENVIRONMENT = os.environ["__ENVIRONMENT__"]
# MAGIC
# MAGIC -- COMMAND ----------
# MAGIC
# MAGIC -- MAGIC %md
# MAGIC -- MAGIC The target catalog depens on the enivronment. Since we are using Unity Catalog we need to use a unqiue name for the catalog. This is the reason why we name the dev silver catalog "silver_dev" for example.
# MAGIC
# MAGIC -- COMMAND ----------
# MAGIC
# MAGIC -- MAGIC %python
# MAGIC -- MAGIC spark.catalog.setCurrentCatalog(f"silver_{ENVIRONMENT}")
# MAGIC
# MAGIC -- COMMAND ----------
# MAGIC
# MAGIC USE SCHEMA tag02;
# MAGIC
# MAGIC -- COMMAND ----------
# MAGIC
# MAGIC CREATE OR REPLACE TABLE dim_scenario
# MAGIC   ( dim_scenario_pk bigint
# MAGIC     GENERATED BY DEFAULT AS IDENTITY
# MAGIC     ,scenario_code STRING NOT NULL 
# MAGIC       COMMENT 'Account Code'
# MAGIC     ,scenario_type STRING
# MAGIC       COMMENT 'The type related to the scenario either O or C'
# MAGIC     ,scenario_group STRING
# MAGIC       COMMENT 'When the scenario code contains ACT then Actual, when it contains FC then Forecast and when it contains BUD then Plan.'
# MAGIC     ,original_scenario_code STRING
# MAGIC       COMMENT 'The extended description of the account'
# MAGIC     ,scenario_description STRING
# MAGIC       COMMENT 'The descriptive text of the scenario'
# MAGIC     ,COD_SCENARIO_PREC STRING
# MAGIC     ,COD_SCENARIO_SUCC STRING
# MAGIC     ,COD_SCENARIO_RIF1 STRING
# MAGIC     ,COD_SCENARIO_RIF2 STRING
# MAGIC     ,COD_SCENARIO_RIF3 STRING
# MAGIC     ,COD_SCENARIO_RIF4 STRING
# MAGIC     ,COD_SCENARIO_RIF5 STRING
# MAGIC     ,COD_AZI_CAPOGRUPPO STRING
# MAGIC     ,scenario_currency_code STRING
# MAGIC       COMMENT 'The currency associated with the scenario'
# MAGIC     ,COD_CATEGORIA_GERARCHIA STRING
# MAGIC     ,COD_CATEGORIA_ELEGER STRING
# MAGIC     ,COD_ESERCIZIO STRING
# MAGIC     ,scenario_version_description STRING
# MAGIC       COMMENT 'The version description or identification related to the scenario'                                                                              
# MAGIC     ,scenario_hash_key STRING
# MAGIC       COMMENT 'Hash value of the dimensional attributes per scenario code'
# MAGIC     ,start_datetime TIMESTAMP NOT NULL 
# MAGIC       COMMENT 'The dimensional start date of the record'
# MAGIC     ,end_datetime TIMESTAMP
# MAGIC       COMMENT 'The dimensional end date of the record, those with a NULL value is curent'                      
# MAGIC     ,is_current INTEGER
# MAGIC       COMMENT 'Flag to indicate if this is the active dimension record per code'
# MAGIC     ,Sys_Gold_InsertedDateTime_UTC TIMESTAMP
# MAGIC       COMMENT 'The timestamp when this record was inserted into gold'
# MAGIC     ,Sys_Gold_ModifiedDateTime_UTC TIMESTAMP
# MAGIC       COMMENT 'The timestamp when this record was last updated in gold'          
# MAGIC ,CONSTRAINT dim_scenario_primary_key PRIMARY KEY(dim_scenario_pk)
# MAGIC   )
# MAGIC
# MAGIC TBLPROPERTIES ('delta.feature.allowColumnDefaults' = 'supported')
# MAGIC CLUSTER BY (scenario_code);
# MAGIC
# MAGIC -- COMMAND ----------
# MAGIC
# MAGIC ALTER TABLE dim_scenario ADD CONSTRAINT dateWithinRange_start_datetime CHECK (start_datetime >= '1900-01-01');
# MAGIC ALTER TABLE dim_scenario ADD CONSTRAINT valid_is_current_value CHECK (is_current IN (1, 0));
# MAGIC

# COMMAND ----------

# MAGIC %md
# MAGIC **Now the table is created we want to insert the unknown member...**

# COMMAND ----------

# MAGIC %py
# MAGIC
# MAGIC sqldf= spark.sql("""
# MAGIC SELECT CAST(-1 AS BIGINT) AS dim_scenario_pk,
# MAGIC        CAST('N/A' AS STRING) AS scenario_code,
# MAGIC        CAST(NULL AS STRING) AS scenario_type,
# MAGIC        CAST(NULL AS STRING) AS scenario_group,
# MAGIC        CAST(NULL AS STRING) AS original_scenario_code,
# MAGIC        CAST(NULL AS STRING) AS scenario_description,
# MAGIC        CAST(NULL AS STRING) AS COD_SCENARIO_PREC,
# MAGIC        CAST(NULL AS STRING) AS COD_SCENARIO_SUCC,
# MAGIC        CAST(NULL AS STRING) AS COD_SCENARIO_RIF1,
# MAGIC        CAST(NULL AS STRING) AS COD_SCENARIO_RIF2,
# MAGIC        CAST(NULL AS STRING) AS COD_SCENARIO_RIF3,
# MAGIC        CAST(NULL AS STRING) AS COD_SCENARIO_RIF4,
# MAGIC        CAST(NULL AS STRING) AS COD_SCENARIO_RIF5,
# MAGIC        CAST(NULL AS STRING) AS COD_AZI_CAPOGRUPPO,
# MAGIC        CAST(NULL AS STRING) AS scenario_currency_code,
# MAGIC        CAST(NULL AS STRING) AS COD_CATEGORIA_GERARCHIA,
# MAGIC        CAST(NULL AS STRING) AS COD_CATEGORIA_ELEGER,
# MAGIC        CAST(NULL AS STRING) AS COD_ESERCIZIO,
# MAGIC        CAST(NULL AS STRING) AS scenario_version_description,
# MAGIC        CAST(NULL AS STRING) AS scenario_hash_key,
# MAGIC        CAST('1900-01-01' AS TIMESTAMP) AS start_datetime,
# MAGIC        CAST(NULL AS TIMESTAMP) AS end_datetime,
# MAGIC        CAST(1 AS INTEGER) AS is_current,
# MAGIC        CAST(NULL AS TIMESTAMP) AS Sys_Gold_InsertedDateTime_UTC,
# MAGIC        CAST(NULL AS TIMESTAMP) AS Sys_Gold_ModifiedDateTime_UTC       
# MAGIC """)
# MAGIC
# MAGIC #display(sqldf)
# MAGIC sqldf.write.mode("append").option("mergeSchema", "true").saveAsTable(f"gold_{ENVIRONMENT}.tag02.dim_scenario")
